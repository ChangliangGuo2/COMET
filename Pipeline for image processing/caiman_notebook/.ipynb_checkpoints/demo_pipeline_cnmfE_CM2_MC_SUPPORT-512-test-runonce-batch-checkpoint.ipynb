{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "    get_ipython().run_line_magic('autoreload', '2')\n",
    "    get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"caiman.log\",\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import inspect_correlation_pnr, nb_inspect_correlation_pnr\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "from caiman.source_extraction.cnmf.initialization import init_neurons_corr_pnr\n",
    "from caiman.utils.visualization import view_quilt\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_file = [r'H:\\CM2scope_experimental_data\\trace_fear_conditioning\\train\\gzc_rasgrf-ai148d-371\\My_V4_Miniscope\\AMF_despeckle_MC_denoised_8bit.tif'.replace('\\\\','\\\\'),\n",
    "             ]\n",
    "print(fnames_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fnames in fnames_file:\n",
    "    fnames=[fnames]\n",
    "    #%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "    if 'dview' in locals():\n",
    "        cm.stop_server(dview=dview)\n",
    "    c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "        backend='local', n_processes=None, single_thread=False)\n",
    "    \n",
    "    # dataset dependent parameters\n",
    "    frate = 9.3                      # movie frame rate\n",
    "    decay_time = 0.4                 # length of a typical transient in seconds\n",
    "    \n",
    "    # motion correction parameters\n",
    "    motion_correct = False    # flag for performing motion correction\n",
    "    pw_rigid = True         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "    gSig_filt = (5, 5)      # size of high pass spatial filtering, used in 1p data\n",
    "    max_shifts = (20, 20)      # maximum allowed rigid shift\n",
    "    strides = (128, 128)       # start a new patch for pw-rigid motion correction every x pixels\n",
    "    overlaps = (32, 32)      # overlap between pathes (size of patch strides+overlaps)\n",
    "    max_deviation_rigid = 10  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "    border_nan = 'copy'      # replicate values along the boundaries\n",
    "    \n",
    "    num_frames_split = 100  #根据数据量大大小进行更改\n",
    "    \n",
    "    mc_dict = {\n",
    "        'fnames': fnames,\n",
    "        'fr': frate,\n",
    "        'decay_time': decay_time,\n",
    "        'pw_rigid': pw_rigid,\n",
    "        'max_shifts': max_shifts,\n",
    "        'gSig_filt': gSig_filt,\n",
    "        'strides': strides,\n",
    "        'overlaps': overlaps,\n",
    "        'max_deviation_rigid': max_deviation_rigid,\n",
    "        'border_nan': border_nan,\n",
    "        'num_frames_split':num_frames_split\n",
    "    }\n",
    "    \n",
    "    opts = params.CNMFParams(params_dict=mc_dict)\n",
    "    \n",
    "    \n",
    "    fname_new = cm.save_memmap(fnames, base_name='memmap_',order='C', border_to_0=0, dview=dview)\n",
    "    \n",
    "    # load memory mappable file\n",
    "    Yr, dims, T = cm.load_memmap(fname_new)\n",
    "    images = Yr.T.reshape((T,) + dims, order='F')\n",
    "    print(dims)\n",
    "    print(T)\n",
    "    print(Yr.shape)\n",
    "    print(images.shape)\n",
    "    \n",
    "    # parameters for source extraction and deconvolution\n",
    "    p = 1               # order of the autoregressive system\n",
    "    K = None            # upper bound on number of components per patch, in general None\n",
    "    gSig = (2,2)       # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "    gSiz = (7,7)     # average diameter of a neuron, in general 4*gSig+1\n",
    "    Ain = None          # possibility to seed with predetermined binary masks\n",
    "    merge_thr = .7     # merging threshold, max correlation allowed\n",
    "    rf = 80            # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "    stride_cnmf = 24    # amount of overlap between the patches in pixels\n",
    "    #                     (keep it at least large as gSiz, i.e 4 times the neuron size gSig)\n",
    "    tsub = 1            # downsampling factor in time for initialization,\n",
    "    #                     increase if you have memory problems\n",
    "    ssub = 1            # downsampling factor in space for initialization,\n",
    "    #                     increase if you have memory problems\n",
    "    p_ssub = 1\n",
    "    p_tsub = 1\n",
    "    #                     you can pass them here as boolean vectors\n",
    "    low_rank_background = None  # None leaves background of each patch intact,\n",
    "    #                     True performs global low-rank approximation if gnb>0\n",
    "    gnb = -2             # number of background components (rank) if positive,\n",
    "    #                     else exact ring model with following settings\n",
    "    #                         gnb= 0: Return background as b and W\n",
    "    #                         gnb=-1: Return full rank background B\n",
    "    #                         gnb<-1: Don't return background\n",
    "    nb_patch = 0        # number of background components (rank) per patch if gnb>0,\n",
    "    #                     else it is set automatically\n",
    "    min_corr = 0.6   # min peak value from correlation image\n",
    "    min_pnr = 15      # min peak to noise ration from PNR image\n",
    "    ssub_B = 1          # additional downsampling factor in space for background\n",
    "    ring_size_factor = 1.2 # radius of ring is gSiz*ring_size_factor\n",
    "    \n",
    "    bord_px=0\n",
    "    \n",
    "    merge_parallel=True\n",
    "    \n",
    "    \n",
    "    opts.change_params(params_dict={'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "                                    'K': K,\n",
    "                                    'gSig': gSig,\n",
    "                                    'gSiz': gSiz,\n",
    "                                    'merge_thr': merge_thr,\n",
    "                                    'p': p,\n",
    "                                    'tsub': tsub,\n",
    "                                    'ssub': ssub,\n",
    "                                    'p_ssub':p_ssub,\n",
    "                                    'p_tsub':p_tsub,\n",
    "                                    'rf': rf,\n",
    "                                    'stride': stride_cnmf,\n",
    "                                    'only_init': True,    # set it to True to run CNMF-E\n",
    "                                    'nb': gnb,\n",
    "                                    'nb_patch': nb_patch,\n",
    "                                    'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "                                    'low_rank_background': low_rank_background,\n",
    "                                    'update_background_components': False,  # sometimes setting to False improve the results\n",
    "                                    'min_corr': min_corr,\n",
    "                                    'min_pnr': min_pnr,\n",
    "                                    'normalize_init': False,               # just leave as is\n",
    "                                    'center_psf': True,                    # leave as is for 1 photon\n",
    "                                    'ssub_B': ssub_B,\n",
    "                                    'ring_size_factor': ring_size_factor,\n",
    "                                    'del_duplicates': True, # whether to remove duplicates from initialization\n",
    "                                    'merge_parallel':merge_parallel,\n",
    "                                    'method_exp': 'dilate',\n",
    "                                    'border_pix': bord_px})                # number of pixels to not consider in the borders)\n",
    "    \n",
    "    cn_filter, pnr,data_max,data_noise,std = cm.summary_images.correlation_pnr_cuda(images, gSig=2, swap_dim=False,center_psf=True) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "    \n",
    "    \n",
    "    name = fnames[0].split(\".\")[0]+'_variables.pkl'\n",
    "    with open(name, 'wb') as file:\n",
    "        pickle.dump({'cn_filter': cn_filter, 'pnr': pnr, 'data_max': data_max, 'data_noise': data_noise, 'std': std, 'opts': opts}, file)\n",
    "    \n",
    "    name = fnames[0].split(\".\")[0]+'_correlation_images_sigma2.png'\n",
    "    cn_threshold=cn_filter.copy()\n",
    "    cn_threshold[cn_threshold<0]=0\n",
    "    cm.summary_images.save_summary_images(cn_threshold,name)\n",
    "    \n",
    "    name = fnames[0].split(\".\")[0]+'pnr_images_sigma2.png'\n",
    "    cm.summary_images.save_summary_images(pnr,name)\n",
    "    \n",
    "    name = fnames[0].split(\".\")[0]+'_data_max_sigma2.png'\n",
    "    cm.summary_images.save_summary_images(data_max,name)\n",
    "    \n",
    "    name = fnames[0].split(\".\")[0]+'_data_std_sigma2.png'\n",
    "    cm.summary_images.save_summary_images(std,name)\n",
    "    \n",
    "    name = fnames[0].split(\".\")[0]+'_data_noise_sigma2.png'\n",
    "    cm.summary_images.save_summary_images(data_noise,name)\n",
    "    \n",
    "    cnm = cnmf.CNMF(n_processes=n_processes, dview=dview, Ain=Ain, params=opts)\n",
    "    cnm.fit(images)\n",
    "    \n",
    "    rval_lowest =-0.5\n",
    "    SNR_lowest =3\n",
    "    cnn_lowest=0.8\n",
    "    #high threshold\n",
    "    min_SNR = 3.5\n",
    "    r_values_min = 0.8\n",
    "    min_cnn_thr=1\n",
    "    cnm.params.set('quality', {'rval_lowest': rval_lowest,'SNR_lowest': SNR_lowest,'min_SNR': min_SNR,'cnn_lowest':cnn_lowest,\n",
    "                               'rval_thr': r_values_min,'min_cnn_thr':min_cnn_thr,\n",
    "                               'use_cnn': False,'use_ecc': True,'max_ecc': 1.8,'gSig_range': (2.5,3)})\n",
    "    cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "    \n",
    "    print(' ***** ')\n",
    "    print('Number of total components: ', len(cnm.estimates.C))\n",
    "    print('Number of accepted components: ', len(cnm.estimates.idx_components))\n",
    "    \n",
    "    cnm.estimates.rval_lowest =rval_lowest\n",
    "    cnm.estimates.SNR_lowest =SNR_lowest\n",
    "    cnm.estimates.min_SNR = min_SNR\n",
    "    cnm.estimates.r_values_min = r_values_min\n",
    "\n",
    "    name = fnames[0].split(\".\")[0]+'_cnm_estimates.pkl'\n",
    "    with open(name, 'wb') as file:\n",
    "        pickle.dump(cnm.estimates, file)\n",
    "    \n",
    "    #%% plot contour plots of accepted and rejected components\n",
    "    cnm.estimates.plot_contours_nb(img=pnr*cn_filter, idx=cnm.estimates.idx_components,thr=0.8,cmap='hot',thr_method='nrg')\n",
    "    \n",
    "    good_caAct = cnm.estimates.C\n",
    "    good_resid = cnm.estimates.YrA\n",
    "    good_rawFl = good_caAct + good_resid\n",
    "    good_rawFl=good_rawFl.astype(np.float32)\n",
    "    \n",
    "    cnm.estimates.detrend_df_f()\n",
    "    \n",
    "    \n",
    "    sio.savemat(fnames[0].split(\".\")[0]+'_caiman_result.mat',{\"A_neuron_good_idx\":cnm.estimates.idx_components.astype(np.int32),\"A_neuron_bad_idx\":cnm.estimates.idx_components_bad.astype(np.int32),\"C_trace\":cnm.estimates.C.astype(np.float32),\"A_neuron_sparse\":cnm.estimates.A.astype(np.float32),\"C_raw\":good_rawFl,\"detrended_trace\":cnm.estimates.F_dff.astype(np.float32),\"coordinates\":cnm.estimates.coordinates})\n",
    "\n",
    "    del cnm"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
